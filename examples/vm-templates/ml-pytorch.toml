# Nova VM Template: PyTorch ML Workstation
# High-performance machine learning environment with GPU passthrough
# Optimized for: Deep learning research, model training, Jupyter notebooks

project = "ml-pytorch-workstation"

[vm.ml-pytorch]
# Base configuration
image = "/var/lib/nova/images/ubuntu-22.04-ml.qcow2"
cpu = 16
memory = "32Gi"

# GPU Configuration - Auto-detect and passthrough NVIDIA GPU
gpu_passthrough = true
gpu_mode = "auto"  # Automatically selects best available GPU

# Or specify manually:
# gpu_device = "0000:01:00.0"  # Specific PCI address
# gpu_rom = "/var/lib/nova/roms/nvidia-rtx4090.rom"  # Optional ROM file

# Display - Use SPICE for initial setup, then switch to Looking Glass for performance
display = "spice"
# display = "looking-glass"  # Uncomment for near-native GPU performance

# Network
network = "bridge0"

# Storage
disks = [
    { path = "/var/lib/nova/images/ml-pytorch.qcow2", size = "100G", type = "system" },
    { path = "/var/lib/nova/datasets", size = "500G", type = "data", format = "raw" }
]

# Boot options
autostart = false
boot_order = ["hd", "cdrom"]

# Performance tuning
cpu_mode = "host-passthrough"  # Maximum CPU performance
cpu_topology = { sockets = 1, cores = 16, threads = 1 }
hugepages = true  # Enable hugepages for better memory performance
cpu_pinning = true  # Pin vCPUs to physical cores

# NVIDIA optimizations
[vm.ml-pytorch.nvidia]
cuda_version = "12.1"
cudnn_version = "8.9"
nvidia_driver = "open"  # Use nvidia-open kernel module
compute_mode = "default"  # or "exclusive_process" for single-user
persistence_mode = true

# Pre-installed software via cloud-init
[vm.ml-pytorch.software]
packages = [
    "python3.11",
    "python3-pip",
    "python3-venv",
    "build-essential",
    "git",
    "tmux",
    "htop",
    "nvtop",  # NVIDIA GPU monitoring
]

python_packages = [
    "torch==2.1.0",
    "torchvision==0.16.0",
    "torchaudio==2.1.0",
    "jupyter",
    "jupyterlab",
    "pandas",
    "numpy",
    "matplotlib",
    "scikit-learn",
    "tensorboard",
    "wandb",
    "transformers",
    "accelerate",
    "datasets",
]

# Jupyter Lab configuration
[vm.ml-pytorch.jupyter]
enabled = true
port = 8888
password_hash = ""  # Set your jupyter password hash
token = ""  # Or use token authentication
notebooks_dir = "/home/user/notebooks"

# Container integration for microservices
[container.tensorboard]
capsule = "tensorflow/tensorflow:latest-gpu"
ports = ["6006:6006"]
volumes = [
    "./logs:/logs",
]
network = "nova-ml"
gpu_access = true

[container.mlflow]
capsule = "ghcr.io/mlflow/mlflow:latest"
ports = ["5000:5000"]
volumes = [
    "./mlflow:/mlflow",
]
network = "nova-ml"

# Networking for ML stack
[network.nova-ml]
type = "bridge"
subnet = "192.168.100.0/24"
dhcp = true
dns = true

# Cloud-init user data
[vm.ml-pytorch.cloud_init]
user_data = """
#cloud-config
users:
  - name: mluser
    groups: sudo, docker
    shell: /bin/bash
    sudo: ['ALL=(ALL) NOPASSWD:ALL']
    ssh_authorized_keys:
      - ssh-rsa AAAAB3... your-ssh-key-here

# Install CUDA toolkit
runcmd:
  - wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
  - dpkg -i cuda-keyring_1.0-1_all.deb
  - apt-get update
  - apt-get install -y cuda-toolkit-12-1
  - apt-get install -y nvidia-open
  - echo 'export PATH=/usr/local/cuda-12.1/bin:$PATH' >> /home/mluser/.bashrc
  - echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH' >> /home/mluser/.bashrc

  # Install Docker with NVIDIA runtime
  - curl -fsSL https://get.docker.com -o get-docker.sh
  - sh get-docker.sh
  - distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
  - curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add -
  - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list
  - apt-get update && apt-get install -y nvidia-docker2
  - systemctl restart docker

  # Set up Jupyter Lab
  - su - mluser -c "python3 -m venv /home/mluser/venv"
  - su - mluser -c "/home/mluser/venv/bin/pip install jupyterlab torch torchvision"
  - su - mluser -c "/home/mluser/venv/bin/jupyter lab --generate-config"
"""

# Snapshot policy
[vm.ml-pytorch.snapshots]
enabled = true
schedule = "daily"
retention = 7
auto_snapshot_before_start = false
